Cominciamo caricando il dataset sui vini:
```
data(wine, package='rattle')
```

I dati erano `dim(wine)` 178 righe per 14 colonne, e le variabili sono `names(wine)`.
Vediamo un grafico per avere un'idea di quelle che sono le caratteristiche delle variabili con `pairs(wine)`. Escludendo la variabili `Type` che non e' esplicativa del modello le altre possono servire per cogliere la variabilita' dei dati riguardo ai vini.
Chiamiamo l'oggetto che crea l'analisi delle componenti principali, che e' `pr`.
```
pr <- prcomp(wine[,-1], scale=TRUE)
```
Abbiamo tolto `Type` dal modello, e abbiamo detto a R di scalare le variabili (importante!)
Vediamo che la `dim(wine)` e' come prima, ma i nomi sono:
```
> names(pr)
[1] "sdev"     "rotation" "center"   "scale"    "x"       
```
Dove:
- Rotation sarebbero tutti i vettori dei coefficenti dei phi, ovvero phi_{1,1}, ..., phi_{1,p},...
Se guardiamo le informationi sui loadings, abbiamo che `dim(pr$rotation)` e' una matrice 13x13. Guardiamo le informazioni sulla rotazion[1,1]
```
pr$rotation[1:3,]
```
Invece le x hanno dimensione `dim(pr$x)`, che sono 178 dati su 13 colonne.
Il grafico doppio si ottiene con il comando `biplot`, dove gli passiamo un oggetto e quanto scalare:
```
biplot(pr, scale=0, cex=0.5)
```
I viene etichettati come 81, 160, ecc...sono vini con bassi valori associati con la seconda componente principale (percentuale di alchol bassa ecc ecc) ma hanno alti valori associati con la prima componente principale.
Possiamo fare il grafico di `plot(pr$x[,1:2], col=wine$Type)` per vedere quanta variabilita' individua lo possiamo fare cosi: rappresentiamo tutti gli scores di tutte le componenti principali. Gli facciamo colorare il risultati in base al gruppo: e come colorazione R scegliera' delle colorazioni che rispetteranno il tipo (PC1, PC2, PC3).
Aggiungiamo una legenda anche, con:
```
legend('bottomleft', pch=c(1,1,1), col=c(1,2,3), legend=c('Type 1', 'Type 2', 'Type 3'))
```
Calcoliamo la varianza e la proporzione di varianza spiegata:
```
varianza <- pr$sdev^2
prop.varianza <- varianza/sum(varianza)
```

Se vogliamo vedere assiame possiamo dare
```
par(mfrow=c(1,2))
```
Vediamo il grafico della varianza:
```
plot(prop.varianza, type='l', ylab='Proporzione di varianza spiegata', xlab='Numero delle CP')
```
Proporzione di varianza spiegata
```
plot(cumsum(prop.varianza), type='l', ylab='Proporzione di varianza spiegata', xlab='Numero delle CP')
```
Carichiamo una nuova libreria che dobbiamo installare:
```
install.packages('pls')
library(pls)
```
E carichiamo i dati `data(gasoline)`
Diamo:
```
y <- gasoline$octane
length(y)
X <- gasoline$NIR
dim(X)
```
Iniziamo a scegliere il numero delle componenti tramite la validazione incrociata. Scegliamo il seed(222).
```
set.seed(222)
m <- pcr(y ~ X, validation='CV', scale=TRUE, ncomp=20)
```

Vediamo cosa ci ritorna il summary:
```
> summary(m)
Data: 	X dimension: 60 401 
	Y dimension: 60 1
Fit method: svdpc
Number of components considered: 20

VALIDATION: RMSEP
Cross-validated using 10 random segments.
       (Intercept)  1 comps  2 comps  3 comps  4 comps  5 comps  6 comps
CV           1.543    1.504    1.425   0.3765   0.2718   0.2357   0.2135
adjCV        1.543    1.501    1.420   0.3410   0.2700   0.2338   0.2092
       7 comps  8 comps  9 comps  10 comps  11 comps  12 comps  13 comps
CV      0.2211   0.2167   0.2172    0.2224    0.2180    0.2168    0.2124
adjCV   0.2193   0.2174   0.2138    0.2189    0.2152    0.2129    0.2094
       14 comps  15 comps  16 comps  17 comps  18 comps  19 comps  20 comps
CV       0.2174    0.2211    0.2245    0.2342    0.2378    0.2429    0.2421
adjCV    0.2142    0.2184    0.2209    0.2313    0.2335    0.2373    0.2360

TRAINING: % variance explained
   1 comps  2 comps  3 comps  4 comps  5 comps  6 comps  7 comps  8 comps
X   71.725    88.57    93.74    97.51    98.28    98.67    99.01    99.20
y    8.856    22.69    96.39    97.40    98.18    98.51    98.51    98.57
   9 comps  10 comps  11 comps  12 comps  13 comps  14 comps  15 comps
X    99.36     99.48     99.57     99.64     99.70     99.74     99.78
y    98.79     98.79     98.81     98.88     98.88     98.88     98.88
   16 comps  17 comps  18 comps  19 comps  20 comps
X     99.81     99.83     99.85     99.86     99.88
y     98.93     98.93     99.00     99.05     99.08
```

Come facciamo a scegliere? Per scegliere ci sono due metodi:
1 - Grafico
Dividiamo la finestra in due con il solito comando `par(mfrow=c(1,2))`. Vediamo in base alle componenti principali e allo scarto quadratico medio, e quindi diamo
```
validationplot(m, val.type='MSEP')
validationplot(m, val.type='R2')
```
Ovviamente vanno al contrario: l'errore quadratico medio diminuiscce quando l'R2 aumenta.
2 - Via dati
Scriviamo:
```
> explvar(m)
     Comp 1      Comp 2      Comp 3      Comp 4      Comp 5      Comp 6 
71.72466749 16.84355942  5.16969875  3.77274681  0.77158999  0.38790757 
     Comp 7      Comp 8      Comp 9     Comp 10     Comp 11     Comp 12 
 0.33858298  0.19445609  0.15867287  0.11934739  0.09112767  0.06904035 
    Comp 13     Comp 14     Comp 15     Comp 16     Comp 17     Comp 18 
 0.05728967  0.04483529  0.03255193  0.02972121  0.02271663  0.01849377 
    Comp 19     Comp 20 
 0.01743618  0.01328488 
```
Ora proviamo a disegnare un grafico unico con una retta:
```
plot(explvar(m), type='l')
```

Possiamo notare come ci sia una riduzione pesante delle variabili necessario.
Vediamo un grafico dei coefficenti usando `coefplot`. Dobbiamo dirgli qual e' il modello da cui prendere i coefficenti dei loadings e il numero delle componenti principali:
```
coefplot(m, ncomp=1:5, legendpos='bottomleft')
```
Con tutte le 5 componenti principali scelte.
Sulle ascisse ci sono tutte le componenti, sull'ordinata i coefficenti.
Da questo grafico possiamo vedere come la prima componente [?]
La seconda fa il contrario della prima: dove nella prima c'era piu' peso nella seconda ce n'e' meno e cosi' via. Anche graficamente pesa piu' o meno rispetto a quello che la prima componente principale aveva o meno considerato.
La terza (quella verde) fa ancora qualcosa di diverso: ha dei picchi dove le altre non le avevano: i picchi di solito significano punti di variabilita' che erano rimasti isolati.
La quarta segue la terza, anche se e' un poco staccata. Aggiunge poca variabilita', e infatti lo scarto e' poco.
Alla quinta va a pari passo con la quarta, e gli scarti son piccolissimi.

Oissuani ridare il comando con piu' componenti:
```
coefplot(m, ncomp=1:10, legendpos='bottomleft')
```

Possiamo creare una rappresentazione grafica solo dei coeffincenti, senza il confronto di utilita' delle componenti principali dando semplicemente `coefplot(m)`
Vediamo lo scoreplot:
```
scoreplot(m, comps=1:5, cex=0.5)
```
A questo punto ci serve eseguire semplicemente un grafico del modello per vedere come avere in ascissa i valori misurati e in ordinata quelli aspettati:
```
plot(m)
abline(0,1)
```
Quindi se voglio fare previsione questo modello e' una buona previsione: funziona graficamente, non ci sono outlier e le componenti principali sono una buona soluzione dal punto di vista pratico e dal punto di vista della cross validation. La prossima volta lo confronteremo con le tecniche ridge e lasso, per vedere qual e' nella pratica quella piu' sensata (e piu' comoda)
