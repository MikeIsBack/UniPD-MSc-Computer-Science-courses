06/04/2017

RECAP
=====

Ricarichiamo i dati della volta scorsa:

library (MASS)
data(Boston)
Boston[1:3,]

Che ci dovrebbe dare questo output:

     crim zn indus chas   nox    rm  age    dis rad tax ptratio  black lstat
1 0.00632 18  2.31    0 0.538 6.575 65.2 4.0900   1 296    15.3 396.90  4.98
2 0.02731  0  7.07    0 0.469 6.421 78.9 4.9671   2 242    17.8 396.90  9.14
3 0.02729  0  7.07    0 0.469 7.185 61.1 4.9671   2 242    17.8 392.83  4.03
  medv
1 24.0
2 21.6
3 34.7

Creiamo anche m

m <- lm(medv ~ lstat, data=Boston) # da errore :/

Chiamiamo il summary

summary(m)

Infine avevamo visto come si accedeva alle componenti di m con il comando:

names(m)

Ed avevamo per esempio visto i coefficenti:

m$coefficients

RESIDUI
=======

Come visto a lezione, c'erano due tipi di residui:
- "Classici" ma possono andare fuori scala
- Standardizzati, che chiamiamo e~ che sono i resituidi meno la loro media diviso per la radice quadrata della varianza:
(e-media)/sqrt(varianza)

# Residui classici

I residui classici si possono calcolare tramite questa formula in R:

residui <- residuals(m)

Ora costruiamo un po' di grafici sui residui.
Dividiamo la finestra grafica in due parti:

par(mfrow=c(2,2))

Questo divide l'interfaccia in due righe e in due colonne, riempiendole in senso orario
Iniziamo con l'istogramma dei residui, che si puo' calcolare con il seguente comando:

hist(residui, prob=TRUE)

A questo punto, dovremo avere il nostro grafico. E' possibile notare come la distribuzione non sia tanto simmetrica, e ricorda poco una distribuzione normale (in quanto dovrebbe essere centrata e a campana). Siccome stiamo lavorando con due variabili probabilmente stiamo tralasciando tante cose del modello.
Ora visualizziamo il grafico di dispersione tramite il seguente comando:

plot(residui)

Al grafico di dispersione ora aggiungiamo la retta in 0 in quanto i punti dovrebbero distribuirsi equamente da quella linea. Per far cio' tracciamo la linea con il seguente comando:

abline(h=0)

Dai residui e' possibile vedere:
- Non abbiamo andamenti tipo variabili
- Concentrazione di punti sotto lo zero (e questo non va bene)
- La variabilita' tra 0-100 e' diversa rispetto alla variabilita' che abbiamo in 200-300. Questo e' correlato con il primo istogramma. Questo ci da un'idea del fatto che questo modello non va ancora bene.

Ora vediamo il grafico di dispersione dei redisui rispetto alla variabile esplicativa (lstat). Mettiamo in ascissa la variabile esplicativa, e nell'ordinata invece poniamo i residui. Otteniamo il seguente comando quindi:

plot(Boston$lstat, residui, cex.lab=1.4, cex.axis=1.4)

Per riferimento mettiamo sempre la retta anche passa per lo zero, con il comando

abline(h=0)

Da qui possiamo vedere come il modello non sia completo in quanto e' possibile identificare una parabola.

Ora vediamo i residui contro i residui stimati nel modello. Il comando e':

plot(fitted(m), residui, cex.lab=1.4, cex.axis=1.4)

E tracciamo la solita linea:

abline(h=0)

Questi sono i classici grafici che si fanno in una analisi reale. Di solito pero' si fa:
- Uno dei primi due appena visti
- Andamento dei residui rispetto a tutte le esplicative


---

I residui ci servono per vedere se ci sono dei comportamenti anomali. Si riconoscono se da una nuvola di punti scappa qualche osservazione che si comporta in modo strano. Nel grafico 2 possiamo vedere come per x=500~ c'e' un'osservazione con il residuo molto piu' piccolo.
Come si fanno a vedere problemi per il modello? Ci servono i residui standardizzati. Se i residui sono standardizzati seguono una distribuzione normale, e se vanno bene dovrebbero essere compresi all'interno dell'intervallo (-2,2). Siccome c'e' qualcosa di sospetto quindi guardiamo i residui standardizzati.

# Residui standardizzati

Chiameremo r.standard per i residui standardizzati, che calcoliamo con:

r.standard <- rstandard(m)

Li plottiamo con:

plot(r.standard)

Tracciamo la classica linea

abline(h=0)

Disegniamo i primi due grafici:

plot(Boston$lstat, r.standard, cex.lab=1.4, cex.axis=1.4)

Linea:

abline(h=0)

Segnamo piu' o meno dove i residui standardizzati dovrebbero stare:

abline(h=-2, col='red')
abline(h=2, col='red')

Quando il 95% dei punti stanno dentro le bande va tutto bene. Come ordine di grandezza dei residui quindi ci siamo (al 95%), ma non ci siamo assolutamente con l'andamento deterministico. Dobbiamo anche valutare se con le procedure di R se questi valore che escono (anche se pochi) sono pericolosi/dannosi per il modello. C'e' un comando in R che ci permette di evidenziare queste anomalie.
Chiudiamo la finestra grafica, e diamo il seguente comando:

par(mfrow=c(2,2))

Questo comando ci da una valutazione grafica dei residui:

plot(m)

1 - Nel primo grafico vediamo come sopra il grafico a dispersione R ci indica un andamento che assomiglia ad un andamento a parabola.
2 - Il secondo si chiama "Diagramma grafico quantile quantile" (cucuplot), confronta le caratteristiche dei nostri residui con le caratteristiche di quelli normali. Lui confronta i quantili dei residui con quelli della normale standard. Se il modello andasse bene i quantili dovrebbero essere molto vicini/pari alla bisettriche del primo/terzo quadrante. I quantili teorici sono piu' basi di quelli stimati. R ci segna anche dei potenziali valori sospetti, che riportano delle etichette (i valori estremi sono in alto a destra)
3 - Questo grafico non esisteva tempo fa ed ha una interpretazione molto difficile. Sarebbe come (1) ma con i residui messi in valore assoluto e sotto radice. Potenziali valori anomali sono valori che stanno sopra 1.5 (regola fatta molto a spanne), che possono essere indicati come valori strani (che vengono segnati da R). Questo grafico possiamo anche non interpretarlo, sono piu' importanti gli altri.
4 - Questo grafico scioglie le anomalie sui dati. Questo grafico una volta veniva spezzato (tra (3) e (4)). Ora l'hanno raccolto, e son presenti due informazioni:
- Punti leva
- Distanza di Cook
La cosiddetta leva dei residui e' una informazione calcolata sui residui che ci dice quanto influente e' il residuo sul modello. I punti che si trovano in alto a destra del grafico sono i punti che hanno maggior peso. In questo caso R ce ne segna tre ma in realta' tutti i punti che si trovano li potrebbero essere punti leva. A questo punto come si discrimina se un punto e' anomalo o leva? Con la distanza di Cook
La distanza di Cook e' la quantificazione del peso del punto sospetto e funziona nella seguente maniera:
- Valori > 1 dicono che il punto e' anomalo e che va analizzato a parte. Bisogna cercare le caratteristiche dei dati di quel soggeto, e si riesegue la stima senza quel punto. Come facciamo a vedere se la distanza di Cook e' grande? Vengono rappresentate nel grafico le curve di livello associate alla distanza di Cook. In questo caso ne abbiamo una, ma in futuro vedremo che ce ne saranno molteplici. I punti segnati da R che sono potenziali punti di leva stanno sulla curva di livello 0 e quindi non sono punti anomali. A ciascuna curva viene associato un valore. Quando ce n'e' una si sottointende che sia 0.

Per individuare anomalie nei residui utilizziamo quindi il 4o grafico.

Quindi normalmente si fa:
- Grafico di dispersione
- Plot del modello (per avere questi 4 valori)

# Verifica d'ipotesi/Inferenza sul modello

## Intervallo di confidenza

Costruiamo un intervallo di confidenza per beta1 (lstat) al livello 0.95. [la cosa sara' da fare al compitino]
(beta cappello1 - beta 1)/SE(beta cappello1) e tutto di sidtribuisce con una t di student_{n-2} con n=506 (diventerebbe una N(0,1) grazie alla sua grandezza).
Quindi il conto da fare e':

qt(0.025, df=506-2)

Dove:
- qt specifica i quantili con la distribuzione t di student.
- df = _degree of freadom_ i gradi di liberta' (n) meno 2.
Che ci da:

[1] -1.964682

A livello di compitino ci saranno una serie di quantili tra cui potremmo scegliere. La stima quindi sara'

-0.95005 -qt(0.975, df=506-2)* 0.03873

Che ci da:

[1] -1.026142

E

-0.95005 +qt(0.975, df=506-2)* 0.03873

Che ci da:

[1] -0.8739579

In generale e': stima - tDiStudent * SE

E' un intervallo che non comprende lo 0 e quindi rifiutiamo l'ipotesi che beta1 sia 0, il che combacia con il nostro p-value.
Tutto cio' e' riassumibile nel seguente comando:

confint(m)

Che ci da:

                2.5 %     97.5 %
(Intercept) 33.448457 35.6592247
lstat       -1.026148 -0.8739505


Dove se non specifico il mio intervallo di confidenza e' automaticamente impostato a 0.95. Si puo' impostare il livello personalizzato:

confint(m, level=0.90)

Che ci da:

                  5 %       95 %
(Intercept) 33.626697 35.4809847
lstat       -1.013877 -0.8862212

## Verifica d'ipotesi

Potrebbe essere nel compitino. Solitamente la verifica d'ipotesi e' per 0, ma e' possibile farla per un valore diverso. Proviamo a farlo tra:
- H0: beta1 = -1
- H1: beta1 != -1

Prendiamo il classico livello di soglia alpha=0.005
E' come la formula vista prima, solo che in beta1 ora mettiamo -1 al posto di 0.
Sara:

(beta1 cappello - beta1)/SE(beta1 cappello)

Chiamiamola statistica.t, quindi in R digitiamo:

statistica.t <- (-0.95005 - (-1))/0.03873

Con la statistica.t che varra' 1.289698
Vedento i quantili con la t di student otteniamo:

qt(0.025, df=506-2)

Il valore ottenuto e' -1.964682, che mi permette di dire che non ho evidenza contro H0 al livello 0.05 (perche' 1.289698 sta dentro +-1.964682)

Se usassimo in in quantile con un alpha piu' grande otterrei

qt(0.05, df=506-2)

Ottenendo -1.647883, che come prima mi permette di dire che non ho evidenza contro H0.

### Livello di significativita' osservato del test

Possiamo verificare la probabilita' che [?] con:

pt(statistica.t, df=506-2)

Che ci da una probabilita' pari a 0.9011265.

Per l'alpha osservato dobbiamo prendere il minimo tra:
- P(t_504 > 1.2897)
- P(t_504 < 1.2897)

Che in R possiamo ottenere con i seguenti comandi:

1-pt(statistica.t, df=506-2)
2*(1-pt(statistica.t, df=506-2))

Che mi danno rispettivamente: 0.09887353 e 0.1977471

## Previsione fuori dal training set + Intervallo previsivo

Esiste il comando predict che ha bisogno
- del modello
- dei dati "nuovi", che vanno specificati in maniera particolare. Bisogna passare un dataframe con una lista di quantita'. In questo caso spefichiamo tre possibili valori di lstat e lui in corrispondenza di ciascun valore inserisce la stima di ciascun modello, con la stima superiore e inferiore dell'intervallo previsione
- interval='prediction' ci permette di fare la previsione dell'intervallo

Il comando da dare e':

predict(m, newdata=data.frame(list(lstat=c(5, 10, 25))), interval='prediction')

Che ritorna:

       fit       lwr      upr
1 29.80359 17.565675 42.04151
2 25.05335 12.827626 37.27907
3 10.80261 -1.457504 23.06272

A differenza di fitted(m), predict calcola all'esterno del training set. Se lanciamo il prefict(m) lui lancia automaticamente il fitted(m).

# Modello di regressione multipla

Inseriremo inizialmente altre variabili nel modello. Inizieremo inserendo il rateo di crimine nel modello. Per vedere cosa possiamo inserire digitiamo:

names(Boston)

Inseriamo il tasso di crimine nel grafico per vedere se va bene con il comando:

plot(Boston$crim, Boston$medv, xlab='Crimine', ylab='Prezzo')

Noi eravamo partiti con il modello `m <- lm(medv ~ lstat, data=Boston)
Esistono due possibilita' per variare un modello
1 - Costruiamo un modello allo stesso modo aggiungendo la variabile aggiuntiva. Ovvero:

m2 <- lm(medv ~ lstat + crim, data=Boston)

2 - La versione veloce permette di assegnare all'oggetto un update del modello. Digitiamo:

m2 <- update(m, . ~ . + crim)

Se vogliamo togliere una variabile, al posto di `+` digitiamo `-`.
Se eseguiamo il summary vediamo

summary(m2)

Call:
lm(formula = medv ~ lstat + crim, data = Boston)

Residuals:
    Min      1Q  Median      3Q     Max 
-15.234  -3.987  -1.513   2.138  25.017 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept) 34.31921    0.57374  59.816   <2e-16 ***
lstat       -0.91139    0.04339 -21.004   <2e-16 ***
crim        -0.07045    0.03602  -1.956   0.0511 .  
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 6.198 on 503 degrees of freedom
Multiple R-squared:  0.5476,	Adjusted R-squared:  0.5458 
F-statistic: 304.4 on 2 and 503 DF,  p-value: < 2.2e-16


La statistica test e' quasi sul bordo del rifiuto per crim. In questo caso non la eliminiamo perche' piu' avanti potrebbe cambiare la significativita'.
Cosa e' cambiato rispetto al modello precedente? Ci aspettiamo che almeno l'R^2 sia migliorato. Per il modello iniziale, il valore era 0.5441, mentre per m2 e' 0.5476.
Il RSE (residual standard error) e' diminuito, questo perche' abbiamo aggiunto una variabile.
